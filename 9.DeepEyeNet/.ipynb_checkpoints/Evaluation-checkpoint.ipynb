{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepEyeNet-Image Captioning with key word reinforced\n",
    "## Evaluation Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import h5py\n",
    "\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.models import load_model\n",
    "\n",
    "from model import CaptionModel, KeywordModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file):\n",
    "    with open(file,'r') as f:\n",
    "        return json.load(f)\n",
    "def save_json(data, file):\n",
    "    with open(file,'w') as f:\n",
    "        json.dump(data, f)\n",
    "def load_pickle(file):\n",
    "    with open(file,'rb') as f:\n",
    "        return pickle.load(f)\n",
    "def save_pickle(data, file):\n",
    "    with open(file,'wb') as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_imgs, val_imgs, test_imgs\n",
    "train_imgs = load_pickle('./data/data_path/train_imgs.pkl')\n",
    "val_imgs = load_pickle('./data/data_path/val_imgs.pkl')\n",
    "test_imgs = load_pickle('./data/data_path/test_imgs.pkl')\n",
    "\n",
    "# Important features\n",
    "results = load_pickle('./data/data_path/results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL (No keywords)\n",
    "# Parameters\n",
    "vocab_size = len(results['word2id'])\n",
    "max_len = max([len(x) for x in results['cap_toks'].values()])\n",
    "embedding_size = 300\n",
    "\n",
    "# load model\n",
    "model_obj = CaptionModel(embedding_size, vocab_size, max_len, results['word2id'], results['id2word'])\n",
    "final_model = model_obj.forward()\n",
    "final_model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "final_model = load_model('./model/model_vgg_new.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL (with keywords)\n",
    "# Parameters renewed\n",
    "new_vocab_size = len(results['word2id_keys'])\n",
    "key_max_len = max([len(x) for x in results['keywords_ids'].values()])\n",
    "\n",
    "model_obj_k = KeywordModel(key_max_len, results['keywords_ids'], embedding_size, new_vocab_size,\n",
    "                           vocab_size, max_len, results['word2id'], results['id2word'])\n",
    "final_model_k = model_obj_k.forward()\n",
    "final_model_k.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "final_model_k = load_model('./model/model_vgg_new_keywords.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
