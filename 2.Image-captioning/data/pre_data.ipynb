{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing for Image captioning task\n",
    "## **Part 1**: \n",
    "Download the images whose urls are specified in the training dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch as t\n",
    "\n",
    "# Load Data\n",
    "data_path = 'raw_data/Train_GCC-training.tsv'\n",
    "data = pd.read_csv(data_path, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "# Download the images into imgs/ folder\n",
    "def download(url, filename, i):\n",
    "    if os.path.exists(filename):\n",
    "        print('file exists!')\n",
    "        return\n",
    "    try:\n",
    "        r = requests.get(url, stream=True, timeout=20)\n",
    "        print(\"Download imgs: {} Done\".format(i))\n",
    "        with open(filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    f.flush()\n",
    "        return True\n",
    "    \n",
    "    except:\n",
    "        if os.path.exists(filename):\n",
    "            os.remove(filename)\n",
    "        return False\n",
    "\n",
    "def read_file():\n",
    "    lost_labels = []\n",
    "    if not os.path.exists('imgs'):\n",
    "        os.mkdir('imgs')\n",
    "    \n",
    "    for i, url in enumerate(data.loc[:,1].values):\n",
    "        filename = os.path.join('imgs/','{}.jpg'.format(i))\n",
    "        if not download(url,filename,i):\n",
    "            lost_labels.append(i)\n",
    "        if i == 50000:\n",
    "            break\n",
    "    \n",
    "    return lost_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_labels = read_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image validity test\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from PIL import Image\n",
    "\n",
    "img_data = os.listdir('imgs')\n",
    "a = []\n",
    "for i in range(len(img_data)):\n",
    "    try:\n",
    "        img = Image.open(os.path.join('imgs/'+img_data[i]))\n",
    "    except:\n",
    "        a.append(img_data[i])\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a)):\n",
    "    filename = os.path.join('imgs/'+a[i])\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "        print(\"delete: %d\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3020\n"
     ]
    }
   ],
   "source": [
    "img_data = os.listdir('imgs')\n",
    "img_data = list(map(lambda x: x.split('.')[0], img_data))\n",
    "img_data = sorted([int(i) for i in img_data if i != ''])\n",
    "lost_data = sorted(list(set(range(50001)).difference(set(img_data))))\n",
    "print(len(lost_data))\n",
    "\n",
    "# image id dictionary\n",
    "# 0.jpg -> 0\n",
    "id2ix = {str(item)+'.jpg': ix for ix, item in enumerate(img_data)}\n",
    "# 0-> 0.jpg\n",
    "ix2id = {item: id for item, ix in (id2ix.items())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 2**: \n",
    "Deal with the text data and store information for the following use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = {str(i)+'.jpg': caption.split() for i, caption in enumerate(data.loc[:50001,0].values) if i not in lost_data}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word id dictionary\n",
    "word_nums = {}\n",
    "def count(word_nums):\n",
    "    def count_word(word):\n",
    "        word_nums[word] = word_nums.get(word,0)+1\n",
    "        return None\n",
    "    return count_word\n",
    "lambda_ = count(word_nums)\n",
    "\n",
    "_ = {lambda_(word) for _,caption in captions.items() for word in caption}\n",
    "word_nums = sorted(word_nums.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [x[0] for x in word_nums if x[1] >= 2 and len(x[0]) <= 12]\n",
    "words = [\"<START>\", \"<EOS>\", \"<UNK>\", \"<PAD>\"]+words\n",
    "word2ix = {word: ix for ix, word in enumerate(words)}\n",
    "ix2word = {ix: word for word, ix in word2ix.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_(words):\n",
    "    word_list = []\n",
    "    for word in words:\n",
    "        if word in word2ix:\n",
    "            word_list.append(word2ix[word])\n",
    "        else:\n",
    "            word_list.append(word2ix[\"<UNK>\"])\n",
    "    return word_list\n",
    "captions_list = [lambda_(words) for key, words in captions.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save file in caption.pth\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "        'captions': captions,\n",
    "        'captions_list': captions_list,\n",
    "        'word2ix': word2ix,\n",
    "        'ix2word': ix2word,\n",
    "        'id2ix': id2ix,\n",
    "        'ix2id': ix2id,\n",
    "}\n",
    "t.save(results, \"caption.pth\")\n",
    "print('save file in caption.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'public', 'fountain', 'turned', 'into', 'a', 'pool', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46979"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = t.load('caption.pth')\n",
    "print(results['captions']['49998.jpg'])\n",
    "results['id2ix']['49998.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
